---
title: "Predicting Continuous Outcomes"
format: html
editor: visual
---


In this tutorial, we’ll use `fastml` to tackle a regression problem—specifically, predicting house sale prices. Just like in classification, the `fastml()` function streamlines the entire modeling workflow for continuous targets with minimal setup.

You’ll see how it:

- Automatically handles data splitting and preprocessing,

- Applies appropriate resampling methods (like cross-validation),

- Tunes hyperparameters across multiple regression algorithms,

- Compares model performance using metrics such as RMSE and R².

Whether you’re forecasting prices, estimating risk scores, or predicting any numeric outcome, `fastml()` makes regression modeling just as effortless and reproducible as classification. Let’s walk through a real-world example step by step.


------------------------------------------------------------------------

## 1. Load Packages and Data

In this regression example, we’ll use a medical dataset to predict a continuous outcome—specifically, Body Mass Index (BMI) based on various clinical features. This simulates a common scenario in healthcare: estimating a patient's health metric using routine measurements.

We’ll use the Pima Indians Diabetes dataset, available via the `mlbench` package. It contains health data from adult female patients of Pima Indian heritage.

```{r, warning=FALSE}
library(fastml)
library(dplyr)
library(mlbench)

data(PimaIndiansDiabetes)

# Prepare dataset: rename 'mass' to 'BMI' and drop 'diabetes'
pima_reg <- PimaIndiansDiabetes %>%
  rename(BMI = mass) %>%
  select(-diabetes) %>%
  filter(BMI > 0)  # remove invalid BMI values (e.g., 0)

head(pima_reg)
```

The resulting dataset includes 768 rows and 8 predictor variables:

- **pregnant**: Number of times pregnant,

- **glucose**: Plasma glucose concentration,

- **pressure**:	Diastolic blood pressure (mm Hg),

- **triceps**: Triceps skin fold thickness (mm),

- **insulin**: 2-hour serum insulin (μU/mL),

- **BMI**: Body mass index (target variable here),

- **pedigree**: Diabetes pedigree function

- **age**: Age in years


In the next step, we'll explore the dataset and launch a full regression workflow using fastml().



------------------------------------------------------------------------

## 2. Train Several Regression Models

With the dataset prepared, we can now use `fastml()` to train and evaluate multiple regression models in a single step. Just like in classification, the function takes care of splitting the data, preprocessing, resampling, and hyperparameter tuning.

In this example, we'll train four common regression algorithms to predict BMI:

- Linear regression (`linear_reg`)

- Support Vector Machine with radial kernel (`svm_rbf`)

- Random Forest (`rand_forest`)

- LightGBM (`lightgbm`)

Let’s run the full pipeline:

```{r, message=FALSE, warning=FALSE}
result <- fastml(
  data       = pima_reg,
  label      = "BMI",
  algorithms = c("linear_reg", "svm_rbf", "rand_forest", "lightgbm")
)
```


**What happens under the hood?**

1.  **Recipe**: median‑imputes NAs, one‑hot‑encodes categoricals, centres & scales numerics.
2.  **Resampling**: 10‑fold CV within the train split.
3.  **Tuning grids**: automatically generated per algorithm.
4.  **Finalisation**: the best hyper‑parameters are selected and the workflow refit on the full training data.

You don’t need to worry about creating resampling objects or preprocessing steps manually—everything is handled internally, while remaining fully customizable via optional arguments.

In the next section, we'll examine and compare the performance of the trained regression models using summary metrics like RMSE and R-squared.

------------------------------------------------------------------------

## 3. Compare Model Performance

After training, you can evaluate how each model performed using the summary() function. This provides a comprehensive overview of model performance based on regression metrics such as:

- **RMSE** (Root Mean Squared Error): Measures average prediction error magnitude.

- *R-squared* (Coefficient of Determination): Indicates how well the model explains variability in the outcome.

- **MAE** (Mean Absolute Error): Average absolute difference between predicted and actual values.

To view the results:

```{r}
summary(result, type = "metrics")
```
From this output, we see that the lightgbm model achieved the lowest RMSE, indicating the most accurate predictions overall. It also has the highest R-squared, suggesting it explains a greater portion of variance in BMI compared to other models.

You can also plot the performance of all models across metrics using:

```{r}
plot(result, type = "bar")
```
This generates a faceted bar plot, making it easy to compare RMSE, R-squared, and MAE visually.

In the next step, we’ll take a closer look at the best model's tuned hyperparameters.


------------------------------------------------------------------------

## 4. Inspect the Best Model

Once the models have been trained and evaluated, `fastml()` automatically identifies the best-performing model based on the optimization metric you specified (e.g., RMSE). You can inspect which model was selected and view its internal details using:

```{r}
result$best_model_name
```

This tells us that the best-performing model is a LightGBM gradient boosting machine.

To view the trained model’s workflow—including the preprocessing steps, model specification, and tuning results—use:

```{r}
result$best_model
```

This reveals:

- The full tidymodels workflow, including the recipe and the fitted model.

- The model engine and its finalized hyperparameters.

- A summary of the training process and resampling results.

This confirms that:

- Preprocessing included zero-variance filtering, dummy encoding (if applicable), centering, and scaling.

- The model is a boosted tree trained with LightGBM, using 100 trees.

You can also retrieve the exact hyperparameters selected during tuning using:

```{r}
summary(result, type = "params")
```

This level of detail is helpful for understanding model complexity, reproducibility, and for future deployment.

In the next section, we’ll use the selected model to make predictions on new, unseen data.

## 5. Predict on New Observations

Once you've identified and reviewed the best model, you can use it to make predictions on new, unseen data. 

Start by sampling a few observations from the dataset (or use an external dataset if available):

```{r}
# Sample 5 new observations
new_obs <- pima_reg %>% 
  slice_sample(n = 5) %>% 
  dplyr::select(-BMI) 

new_obs
```

Use the predict() function to generate predicted BMI values:

```{r}
predict(result, new_obs)
```

------------------------------------------------------------------------

## 6. Variable Importance & SHAP Values

In medical and clinical applications, understanding how a model arrives at its prediction is often just as crucial as the prediction itself. For this reason, `fastml` provides SHAP (Shapley Additive Explanations) support via the `fastexplain()` function—allowing you to interpret individual-level predictions from your best model.

To compute and visualize SHAP values:

```{r}
fastexplain(result)
```

This produces two key plots:

**Feature Importance (Permutation-Based)**

- This plot shows how much the model’s RMSE increases when each feature is permuted (i.e., randomly shuffled).

- The larger the increase in error, the more important the feature is to the model's performance.

- Triceps skinfold thickness is by far the most important feature, followed by glucose, blood pressure, and age.

**SHAP Values (Local Explainability)**

- SHAP values break down each individual prediction into feature-level contributions.

- Positive SHAP values increase the predicted BMI; negative ones decrease it.

- In this example:

  - Triceps and pressure have strong positive contributions.

  - Pregnancy count and age tend to lower BMI predictions for certain individuals.

  - Glucose and pedigree show more mixed or subtle effects.
  
**Interpretation Highlights**

- Triceps consistently emerges as the most influential variable, both globally and locally.

- Some variables (like glucose) may be important for prediction accuracy (as seen in the permutation plot) but may not contribute uniformly across all patients (as reflected in SHAP values).

- SHAP plots also help identify non-linear or interaction effects—for example, how pregnant affects predictions differently depending on other inputs.

------------------------------------------------------------------------




